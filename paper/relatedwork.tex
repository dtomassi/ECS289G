\section{Related Work}
\label{sec:relatedwork}

In \cite{DeepNeuralNetworks}, the authors propose a deep neural network based on contextual long short-term memory (LSTM) architecture. They exploit both the content and metadata to detect bots at the tweet level. They extracted contextual features from user metadata and fed as auxiliary input  to LSTM deep nets processing the tweet text. They also proposed a technique based on synthetic minority oversampling to generate large dataset, suitable for deep nets training, from a minimum amount of labeled data. They demonstrated that with their architecture they achieved high classification accuracy (AUC \textgreater $96$\%) in separating bots from humans. When they applied the same architecture to account-level bot bot detection, they achieved nearly perfect classification accuracy (AUC \textgreater $99$\%). In \cite{DetectingSpamAccounts}, the authors propose a novel approach for distinguishing spam from no-spam social media post. They optimized a set of features independent of historical tweets. These tweets were available only for a short time on Twitter. Account features related to users were taken into account. They observed that an average automated spam account posted at-least  $12$ tweets a day at well defined periods. Their approach achieved a significant improvement on performance when compared to exiting spam detection techniques.